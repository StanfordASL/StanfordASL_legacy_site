<!DOCTYPE html>
<html>
<head>
    



    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Daniele Gammelli</title>

    <meta name="description" content="Learning-based control, mobility systems, autonomous spacecraft">
    <!-- Bootstrap Core CSS -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous"> -->
    <!-- <link rel="stylesheet" href="/css/bootstrap.min.css"> -->
    <link href="https://fonts.googleapis.com/css?family=Montserrat:300,600" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Raleway:400,700" rel="stylesheet">

	<!-- JabRef CSS -->
	<link rel="stylesheet" href="/css/JabRef.css">
	 
    <link rel="canonical" href="http://asl.stanford.edu/people/daniele-gammelli/"> 
    <!-- Not required -->
    <!-- <link rel="alternate" type="application/rss+xml" title="Autonomous Systems Laboratory" href="https://stanfordasl.github.io /feed.xml "> -->
    <!-- Custom Fonts -->
	<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <!-- <link href="css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    
    <!-- My CSS -->
    <link rel="stylesheet" href="/css/my.css"> 

    <!-- Analytics -->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-124680200-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-124680200-1');
    </script>
    

    <!-- Favicons -->
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#2864b7">
    <meta name="msapplication-TileColor" content="#2864b7">
    <meta name="theme-color" content="#ffffff">

</head>





  <body id="page-top" class="index">
    <!-- Navigation -->
<nav id="mainNav" class="navbar navbar-default navbar-custom"> <!-- navbar-fixed-top -->
    <div class="container navbar-items">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="row">
            <div class="col-md-3" style="z-index: 1;">
                <div class="navbar-header page-scroll">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/">
                        <img src="/img/ASL_Logo_White.png" alt="">
                    </a>
                </div>
            </div>
            <div class="col-md-9">
                <div class="row">
                    <!-- Collect the nav links, forms, and other content for toggling -->
                    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                        <ul class="nav navbar-nav navbar-right">
                            <li class="hidden">
                                <a href="#page-top"></a>
                            </li>
                            <!-- 
                            <li class="page-scroll">
                                <a href="/">Home</a>
                            </li>
                             -->
                            
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                                    
                                    <li class="page-scroll">
                                        <a href="/projects/">Projects</a>
                                    </li>
                                    
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                                    
                                    <li class="page-scroll">
                                        <a href="/publications/">Publications</a>
                                    </li>
                                    
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                                    
                                    <li class="page-scroll">
                                        <a href="/people/">People</a>
                                    </li>
                                    
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                                    
                                    <li class="page-scroll">
                                        <a href="/faq/">FAQ</a>
                                    </li>
                                    
                                
                            
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container-fluid -->
</nav>

    <header>
      <div class="container">
        <div class="row" style="margin-top: 40px;">
  	      <div class="col-md-5" style="margin-bottom: 20px;">
  	          <img src="../../img/people/DanieleGammelli.jpg" alt="Daniele Gammelli" class="img-responsive">

            
            <h3>Contacts:</h3>

            
            <div>
              <strong>Email:</strong> gammelli <i>at</i> stanford <i>dot</i> edu
            </div>
            

            

            

            <div style="margin-top:10px;">
              

              
              <span style="margin-right:10px;">
                <a href="https://github.com/DanieleGammelli" target="_blank" title="Github">
                  <i class="fa fa-github fa-2x" style="color:black;"></i>
                </a>
              </span>
              

              
              <span style="margin-right:10px;">
                <a href="https://www.linkedin.com/in/daniele-gammelli-282b36149" target="_blank" title="LinkedIn">
                  <i class="fa fa-linkedin-square fa-2x" style="color:black;"></i>
                </a>
              </span>
              

              
              <span style="margin-right:10px;">
                <a href="https://scholar.google.com/citations?user=C9ZbB3cAAAAJ&hl" target="_blank" title="Google Scholar">
                  <i class="fa fa-graduation-cap fa-2x" style="color:black;"></i>
                </a>
              </span>
              

              
            </div>
  		    </div>
    		  <div class="col-md-7">
            <h2 style="margin-top: 0px;">Daniele Gammelli</h2>
    		    <hr>
            <p>Daniele Gammelli is a postdoctoral scholar in Stanford’s Autonomous Systems Lab, where he focuses on developing learning-based solutions that enable the deployment of future autonomous systems in complex environments, with an emphasis on large-scale robotic networks, mobility systems and autonomous spacecraft. He received his Ph.D. in Machine Learning and Mathematical Optimization at the Technical University of Denmark, where he developed ML-based solutions to analyze and control future Intelligent Transportation Systems.</p>

<p>More broadly, his research interests include deep reinforcement learning, generative models, graph neural networks, bayesian statistics, and control techniques leveraging these tools.</p>

<p>Beyond research, Daniele enjoys practicing soccer, going on trail runs, reading, and cooking.</p>

<h3 id="awards">Awards:</h3>
<ul>
  <li>Kaj and Hermilla Ostenfeld’s Excellence Research Fund</li>
</ul>

            <br>
            
    		  </div>
  		</div>
      <div class="row">
        <div class="col-md-12">
        
          <h2 style="margin-top: 0px;">ASL Publications</h2>
          
            
            
            <ol class="bibliography"><li>
 


<span class="entry" id="GammelliHarrisonEtAl2023">D. Gammelli, J. Harrison, K. Yang, M. Pavone, F. Rodrigues, and F. C. Pereira, <a class="entry-title" href="">“Graph Reinforcement Learning for Network Control via Bi-Level Optimization,”</a> in <i>Int. Conf. on Machine Learning</i>, 2023.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('GammelliHarrisonEtAl2023','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('GammelliHarrisonEtAl2023','abstract')">Abstract</a>]</p>
<span id="abs_GammelliHarrisonEtAl2023" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Dynamic network flow models have been extensively studied and widely used in the past decades to formulate many problems with great real-world impact, such as transportation, supply chain management, power grid control, and more. Within this context, time-expansion techniques currently represent a generic approach for solving control problems over dynamic networks. However, the complexity of these methods does not allow traditional approaches to scale to large networks, especially when these need to be solved recursively over a receding horizon (e.g., to yield a sequence of actions in model predictive control). Moreover, tractable optimization-based approaches are often limited to simple linear deterministic settings and are not able to handle environments with stochastic, non-linear, or unknown dynamics. In this work, we present dynamic network flow problems through the lens of reinforcement learning and propose a graph network-based framework that can handle a wide variety of problems and learn efficient algorithms without significantly compromising optimality. Instead of a naive and poorly-scalable formulation, in which agent actions (and thus network outputs) consist of actions on edges, we present a two-phase decomposition. The first phase consists of an RL agent specifying desired outcomes to the actions. The second phase exploits the problem structure to solve a convex optimization problem and achieve (as best as possible) these desired outcomes. This formulation leads to dramatically improved scalability and performance. We further highlight a collection of features that are potentially desirable to system designers, investigate design decisions, and present experiments showing the utility, scalability, and flexibility of our framework.</p>
</span>
<span id="bib_GammelliHarrisonEtAl2023" class="bibtex noshow">
	<pre>@inproceedings{GammelliHarrisonEtAl2023,
  author = {Gammelli, D. and Harrison, J. and Yang, K. and Pavone, M. and Rodrigues, F. and Pereira, F. C.},
  title = {Graph Reinforcement Learning for Network Control via Bi-Level Optimization},
  booktitle = {{Int. Conf. on Machine Learning}},
  year = {2023},
  month = apr,
  keywords = {pub},
  owner = {gammelli},
  timestamp = {2023-04-25}
}
</pre>
</span>
<!-- <span id="key_GammelliHarrisonEtAl2023" >
	<b>Keywords</b>:
	pub
</span> --></li>
<li>
 


<span class="entry" id="GammelliYangEtAl2022">D. Gammelli, K. Yang, J. Harrison, F. Rodrigues, F. Pereira, and M. Pavone, <a class="entry-title" href="https://arxiv.org/abs/2202.07147">“Graph Meta-Reinforcement Learning for Transferable Autonomous Mobility-on-Demand,”</a> in <i>ACM Int. Conf. on Knowledge Discovery and Data Mining</i>, 2022.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('GammelliYangEtAl2022','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('GammelliYangEtAl2022','abstract')">Abstract</a>]</p>
<span id="abs_GammelliYangEtAl2022" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Autonomous Mobility-on-Demand (AMoD) systems represent an attractive alternative to existing transportation paradigms, currently challenged by urbanization and increasing travel needs. By centrally controlling a fleet of self-driving vehicles, these systems provide mobility service to customers and are currently starting to be deployed in a number of cities around the world. Current learning-based approaches for controlling AMoD systems are limited to the <i>single-city</i> scenario, whereby the service operator is allowed to take an unlimited amount of operational decisions within the same transportation system. However, real-world system operators can hardly afford to fully re-train AMoD controllers for every city they operate in, as this could result in a high number of poor-quality decisions during training, making the single-city strategy a potentially impractical solution. To address these limitations, we propose to formalize the multi-city AMoD problem through the lens of meta-reinforcement learning (meta-RL) and devise an actor-critic algorithm based on recurrent graph neural networks. In our approach, AMoD controllers are explicitly trained such that a small amount of experience within a new city will produce good system performance. Empirically, we show how control policies learned through meta-RL are able to achieve near-optimal performance on unseen cities by learning rapidly adaptable policies, thus making them more robust not only to novel environments, but also to distribution shifts common in real-world operations, such as special events, unexpected congestion, and dynamic pricing schemes.</p>
</span>
<span id="bib_GammelliYangEtAl2022" class="bibtex noshow">
	<pre>@inproceedings{GammelliYangEtAl2022,
  author = {Gammelli, D. and Yang, K. and Harrison, J. and Rodrigues, F. and Pereira, F. and Pavone, M.},
  booktitle = {{ACM Int. Conf. on Knowledge Discovery and Data Mining}},
  title = {Graph Meta-Reinforcement Learning for Transferable Autonomous Mobility-on-Demand},
  year = {2022},
  keywords = {pub},
  owner = {gammelli},
  url = {https://arxiv.org/abs/2202.07147},
  timestamp = {2022-03-02}
}
</pre>
</span>
<!-- <span id="key_GammelliYangEtAl2022" >
	<b>Keywords</b>:
	pub
</span> --></li>
<li>
 


<span class="entry" id="GammelliHarrisonEtAl2022">D. Gammelli, J. Harrison, K. Yang, M. Pavone, F. Rodrigues, and P. C. Francisco, <a class="entry-title" href="">“Graph Reinforcement Learning for Network Control via Bi-Level Optimization,”</a> in <i>Learning on Graphs Conference</i>, 2022.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('GammelliHarrisonEtAl2022','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('GammelliHarrisonEtAl2022','abstract')">Abstract</a>]</p>
<span id="abs_GammelliHarrisonEtAl2022" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Dynamic network flow models have been extensively studied and widely used in the past decades to formulate many problems with great real-world impact, such as transportation, supply chain management, power grid control, and more. Within this context, time-expansion techniques currently represent a generic approach for solving control problems over dynamic networks. However, the complexity of these methods does not allow traditional approaches to scale to large networks, especially when these need to be solved recursively over a receding horizon (e.g., to yield a sequence of actions in model predictive control). Moreover, tractable optimization-based approaches are often limited to simple linear deterministic settings and are not able to handle environments with stochastic, non-linear, or unknown dynamics. In this work, we present dynamic network flow problems through the lens of reinforcement learning and propose a graph network-based framework that can handle a wide variety of problems and learn efficient algorithms without significantly compromising optimality. Instead of a naive and poorly-scalable formulation, in which agent actions (and thus network outputs) consist of actions on edges, we present a two-phase decomposition. The first phase consists of an RL agent specifying desired outcomes to the actions. The second phase exploits the problem structure to solve a convex optimization problem and achieve (as best as possible) these desired outcomes. This formulation leads to dramatically improved scalability and performance. We further highlight a collection of features that are potentially desirable to system designers, investigate design decisions, and present experiments showing the utility, scalability, and flexibility of our framework.</p>
</span>
<span id="bib_GammelliHarrisonEtAl2022" class="bibtex noshow">
	<pre>@inproceedings{GammelliHarrisonEtAl2022,
  author = {Gammelli, D. and Harrison, J. and Yang, K. and Pavone, M. and Rodrigues, F. and Francisco, Pereira C.},
  booktitle = {{Learning on Graphs Conference}},
  title = {Graph Reinforcement Learning for Network Control via Bi-Level Optimization},
  year = {2022},
  keywords = {pub},
  owner = {gammelli},
  timestamp = {2022-11-24}
}
</pre>
</span>
<!-- <span id="key_GammelliHarrisonEtAl2022" >
	<b>Keywords</b>:
	pub
</span> --></li>
<li>
 


<span class="entry" id="GammelliYangEtAl2021">D. Gammelli, K. Yang, J. Harrison, F. Rodrigues, F. C. Pereira, and M. Pavone, <a class="entry-title" href="https://arxiv.org/abs/2104.11434">“Graph Neural Network Reinforcement Learning for Autonomous Mobility-on-Demand Systems,”</a> in <i>Proc. IEEE Conf. on Decision and Control</i>, 2021.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('GammelliYangEtAl2021','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('GammelliYangEtAl2021','abstract')">Abstract</a>]</p>
<span id="abs_GammelliYangEtAl2021" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Autonomous mobility-on-demand (AMoD) systems represent a rapidly developing mode of transportation wherein travel requests are dynamically handled by a coordinated fleet of robotic, self-driving vehicles. Given a graph representation of the transportation network - one where, for example, nodes represent areas of the city, and edges the connectivity between them - we argue that the AMoD control problem is naturally cast as a node-wise decision-making problem. In this paper, we propose a deep reinforcement learning framework to control the rebalancing of AMoD systems through graph neural networks. Crucially, we demonstrate that graph neural networks enable reinforcement learning agents to recover behavior policies that are significantly more transferable, generalizable, and scalable than policies learned through other approaches. Empirically, we show how the learned policies exhibit promising zero-shot transfer capabilities when faced with critical portability tasks such as inter-city generalization, service area expansion, and adaptation to potentially complex urban topologies.</p>
</span>
<span id="bib_GammelliYangEtAl2021" class="bibtex noshow">
	<pre>@inproceedings{GammelliYangEtAl2021,
  author = {Gammelli, D. and Yang, K. and Harrison, J. and Rodrigues, F. and Pereira, F. C. and Pavone, M.},
  title = {Graph Neural Network Reinforcement Learning for Autonomous Mobility-on-Demand Systems},
  year = {2021},
  url = {https://arxiv.org/abs/2104.11434},
  owner = {jh2},
  booktitle = {{Proc. IEEE Conf. on Decision and Control}},
  timestamp = {2021-03-23}
}
</pre>
</span>
<!-- <span id="key_GammelliYangEtAl2021" >
	<b>Keywords</b>:
	
</span> --></li></ol>
          
        
        </div>
      </div>
	  </div>
    </header>
    <!--
The website should work without any of the JS below. -F
-->

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>
<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>
<!-- Plugin JavaScript -->
<!-- <script src="js/jquery.easing.min.js"></script> -->
<!-- Contact Form JavaScript -->
<!-- <script src="js/jqBootstrapValidation.js"></script> -->
<!-- <script src="js/contact_me.js"></script> -->
<!-- Custom Theme JavaScript -->
<!-- <script src="js/freelancer.min.js"></script> -->
<!-- JabRef (Toggling info on Publications Page) -->
<script src="/js/JabRef_QuickSearch.js"></script>

    <!-- Footer -->

<!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
<!-- <div class="scroll-top page-scroll hidden-lg hidden-md">
    <a class="btn btn-primary" href="#page-top">
        <i class="fa fa-chevron-up"></i>
    </a>
</div> -->

<!-- Made with (L) by Federico in October 2017
CSS: Bootstrap (without the JS)
http://getbootstrap.com/
Bloated, but so convenient.
Plus, it's probably already in your browser cache (hence the CDN).
If you want the Jekyll project for your own website,
feel free to drop me a line!
-F
-->

<!-- <hr class="footer-line"/> -->
<script type="text/javascript">
function footerAlign() {
  $('footer').css('display', 'block');
  $('footer').css('height', 'auto');
  var footerHeight = $('footer').outerHeight();
  $('body').css('padding-bottom', footerHeight);
  $('footer').css('height', footerHeight);
}


$(document).ready(function(){
  footerAlign();
});

$( window ).resize(function() {
  footerAlign();
});
</script>

<footer class="footer">
<div id="social-icons">
  <a href="https://twitter.com/stanfordasl" target="_blank"><img src="/img/ASL_twitter.png" alt=""></a>
  <a href="https://www.instagram.com/stanfordasl" target="_blank"><img src="/img/ASL_instagram.png" alt=""></a>
  <a href="https://github.com/StanfordASL" target="_blank"><img src="/img/ASL_github.png" alt=""></a>
</div>
<div class="copyright-text">
  © Autonomous Systems Lab 2021. All rights reserved.
</div>
</footer>

  </body>
</html>
